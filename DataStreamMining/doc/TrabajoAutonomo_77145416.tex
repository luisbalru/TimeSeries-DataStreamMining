\input{preambuloSimple.tex}
\graphicspath{ {./images/} }
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{soul}


%----------------------------------------------------------------------------------------
%	TÍTULO Y DATOS DEL ALUMNO
%----------------------------------------------------------------------------------------

\title{	
\normalfont \normalsize 
\textsc{\textbf{Series Temporales y Minería de Flujos de Datos (2019-2020)} \\ Máster Oficial Universitario en Ciencia de Datos e Ingeniería de Computadores \\ Universidad de Granada} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Trabajo Autónomo II: Minería de Flujos de Datos \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Luis Balderas Ruiz \\ \texttt{DNI:77145416N. luisbalderas@correo.ugr.es}} 
 % Nombre y apellidos 


\date{\normalsize\today} % Incluye la fecha actual

%----------------------------------------------------------------------------------------
% DOCUMENTO
%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Muestra el Título

\newpage %inserta un salto de página

\tableofcontents % para generar el índice de contenidos

\listoffigures


%
%\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
%	\centering
%	\includegraphics[scale=0.6]{e1.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
%	\caption{Progresión de la imagen de E en cada iteración} 
%	\label{fig:e1}
%\end{figure}


\section{Teoría}

\subsection{Cuestionario}
\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.65]{cuestionario.jpg}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Cuestionario de teoría} 
	\label{cuestionario}
\end{figure}
\subsection{Problema de clasificación}

La clasificación en minería de flujo de datos es una extensión del enfoque tradicional en el que los datos no se conocen todos de partida, sino que van llegando paulatinamente. En un principio se abordó como un problema de aprendizaje incremental, por ejemplo, con los árboles de decisión tipo Hoeffding, englobados en los VFDT (Very Fast Decision Tree) para casos discretos o VFML, VFDTc, Quantile Summaries o Aproximaciones Gaussianas en el caso continuo. En comparación con algoritmos clásicos como C4.5, el rendimiento es mucho mayor, siendo capaces de procesar, en el caso de VFDT, hasta 1.6 millones de datos en 20 minutos, frente a las 24h necesarias para C4.5. Centrándonos en los dos clasificadores utilizados en la sección 2 de prácticas, HoeffdingTree y HoeffdingAdaptiveTree, podemos decir que HoeffdingTree es un árbol de decisión incremental capaz diseñdo para aprender de flujos de datos masivos, asumiendo que la distribución de los datos no cambia a lo largo del tiempo. Se aprovecha del hecho de que una muestra pequeña puede ser suficiente para aprender cómo separar un atributo de forma óptima. Esta idea se soporta en la cota de Hoeffding, que establece que, con una certeza de $1-\delta$, la media verdadera de una variable aleatoria de rango R no difiere de la media estimada después de $n$ observaciones independientes por más que
$$\epsilon = \sqrt{\frac{R^2 ln(1/\delta)}{2n}}$$

Por su parte, HoeffdingAdaptiveTree usa ADWIN (Adapting Slide Window, un tipo de detector de Concept Drift) para monitorizar el rendimiento de las ramas del árbol y reemplazarlas por otras nuevas cuando su precisión decrezca y si las nuevas  sean más precisas. \\

Sin embargo, sólo se consideran algoritmos de clasificación en flujo de datos cuando, a parte de lo ya comentado, si cada dato se analiza una sola vez y en el momento en el que se recibe. A diferencia del aprendizaje incremental, la minería de flujo de datos concibe la posibilidad de un cambio de concepto durante la llegada de nuevos datos, pudiendo ser incluso datos contradictorios respecto de los que antes se recibieron. Los algoritmos deben identificar y adaptarse a los nuevos datos que van recibiendo (lo que se llama cambio de concepto y tratamos en la siguiente sección). Además, es necesario definir una forma de evaluación del rendimiento de la clasificación. Surge Holdout, basado en la clasificación tradicional, en la que se entrena el modelo sobre unos datos y se evalúa sobre la partición de test. Sin embargo, sólo es válido si el conjunto de test es similar a los datos de entrenamiento actuales. Si se diera un cambio de concepto, este método no sería útil. En consecuencia, es necesario utilizar métodos en los que cada ejemplo individual se usa primero para probar el modelo antes de usarlo para entrenarlo. Cuando la evaluación se realiza intencionadamente en este orden, el modelo siempre se está probando en casos que no ha visto, por lo que no se necesita conjunto de prueba y se entrena sobre el máximo número de elementos posibles. Surgen dos alternativas: la primera, llamada test-then-train, utiliza todos los ejemplos vistos hasta el presente para calcular la precisión. La segunda, prequential, sólo considera los más recientes utilizando una ventana deslizante o factor de decaimiento.  


\subsection{Concept Drift}

El corazón de la minería de flujo de datos, también si nos centramos en clasificación, es que los datos pueden ir variando a lo largo del tiempo. Por tanto, los clasificadores deben ser robustos ante cambios y capaces de adaptarse para seguir haciendo buenas predicciones. La detección de esos cambios, llamados concept drift, se ha dividido en cuatro bloques:

\begin{itemize}
	\item \textbf{Aprendizaje online.} Familia de algoritmos que continuamente actualizan los parámetros del clasificador mientras procesan los datos que van llegando. No todos los clasificadores pueden ejercer un aprendizaje online ya que los datos sólo se pueden visitar una vez, las limitaciones en memoria y procesamiento son independientes de la cantidad de datos procesada y el aprendizaje se puede para en el cualquier momento, no siendo peor que un clasificador entrenado offline con los datos hasta el momento. CVFDT es un ejemplo de VFDT con cambio de concepto
	\item \textbf{CD mediante ventana.} Incorporan mecanismos para olvidar datos antiguos, haciendo que los recientemente llegados sean más relevantes porque contienen características del contexto actual. 
	\item \textbf{CD mediante ensemble.} Incorporan conjuntos de clasificadores elementales, combinando sus salidas y generando una decisión colectiva que puede incrementar la precisión porque el conocimiento es distribuido y, por tanto, más exhaustivo. Por contra, es necesario un abanico de clasificadores diversos. Los enfoques pioneros, ambos con un número fijo de clasificadores que se van sustituyendo en función de la precisión, son SEA (usando voto por mayoría) y AWE (voto ponderado más sofisticado).
\end{itemize}

Otro enfoque, en el que se evita adaptar el proceso de aprendizaje, es detectar cuándo se produce el CD y actuar, reconociendo así los cambios en los flujos de datos no estacionarios de manera precisa y oportuna. Uno de ellos es el método de detección de cambio (DDM (\cite{ddm})) que controla el número de errores producidos por el modelo de aprendizaje durante la predicción. Compara las estadísticas de dos ventanas: la primera contiene todos los datos y la segunda sólo los datos desde el principio hasta que el número de errores aumenta. Se considera que el número de errores en una muestra se modela a través de una distribución binomial. Un aumento significante en el error del algoritmo sugiere que la distribución de la clase está cambiando y, por tanto, el modelo actual es inapropiado. Definen un nivel de precaución y un nivel de cambio que se van evaluando y se actúa en consecuencia. Se actúa de la siguiente manera (\cite{moa-manual}, \cite{ddm}). Para cada punto $i$ de la muestra, el error es la probabilidad de clasificación errónea $p_i$, con una desviación estándar dada por $s_i = \sqrt{p_i (1-p_i)/i}$. Se almacenan los valores de $p_i$ y $s_i$ cuando $p_i+s_i$ alcanza su mínimo valor durante el proceso ($p_{min}$ y $s_{min}$). A partir de ese momento,

\begin{itemize}
	\item Nivel de precaución: $p_i + s_i \geq p_{min} + 2 s_{min}$
	\item Nivel de cambio: $p_i + s_i \geq p_{min} + 3 s_{min}$
\end{itemize} 


También existen propuestas basadas en ventana, como ADWIN (ya comentado antes, en HoeffdingAdaptiveTree), en el que se definen, dada una ventana, dos subventanas lo suficientemente grandes y con medias distintas, para así poder concluir que los valores esperados son diferentes y se pueda eliminar la parte antigua de la ventana. \\

Un inconveniente importante de la detección del CD es la eficiencia. Monitorizar el rendimiento del algoritmo de aprendizaje ralentiza el proceso, siendo así incapaces de abordar problemas que requieren una respuesta muy rápida ante volúmenes de datos muy grandes. En consecuencia, surge el algoritmo HSP (\cite{hsp}) de detección de CD. \\

Sin embargo, la clasificación en flujo de datos es controvertida porque se requiere siempre de un oráculo de forma que cada tupla sea etiquetada. Siendo así, no parece muy interesante entrenar un modelo ya que el oráculo, que siempre está, puede hacer el trabajo del modelo quizá con mayor precisión dada su condición de experto. Además, se requiere que los algoritmos sean muy eficientes ya que deben leer los datos una sola vez y no son almacenados, mientras que el proceso de etiquetado es costoso y resta mucha eficiencia. Todo ello hace que la clasificación, a pesar de su popularidad, no parezca la técnica más idónea dentro de la minería de flujo de datos. \\

Nota: La mayoría de la información aquí recogida es resumen de la documentación dada en clase (\cite{apuntes}).
\newpage
\section{Prácticas}

\subsection{Entrenamiento offline y evaluación posterior}

\subsubsection{Entrenamiento de un clasificador HoeffdingTree estacionario con generador WaveFormGenerator y varias semillas en entrenamiento. HoeffdingTree adaptativo}

Para enfrentar este problema, escribo un pequeño script con la ejecución en línea de órdenes de las sentencias necesarias para evaluar y entrenar un clasificador HoeffdingTree estacionario en primer lugar, y luego un HoeffdingTree adaptativo, que usa ADWIN para monitorizar el rendimiento de las ramas del árbol y las reemplaza por nuevas ramas cuando su precisión decrece y la de la nueva rama es superior (\cite{HA}). Se hacen 30 ejecuciones por cada experimento propuesto, variando la semilla de entrenamiento entre 4 y 34

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{off-code.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Código para la ejecución del Entrenamiento offline} 
	\label{fig:off1}
\end{figure}

Como resultado, al ejecutar la siguiente función, se genera un archivo que almacena los resultados de la precisión en clasificación y del estadístico Kappa:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{off-ev.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Extracción de resultados en el Entrenamiento offline} 
	\label{fig:off2}
\end{figure}

dando lugar a la siguiente tabla de datos:
\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.45]{ejercicio-offline.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resultados de la precisión en clasificación y estadístico Kappa para Entrenamiento offline} 
	\label{fig:off3}
\end{figure}

\subsubsection{¿Cree que algún clasificador es significativamente mejor que el otro?}

A priori, revisando la tabla de resultados, no parece haber gran diferencia entre los dos clasificadores. Sin embargo, para asegurar la respuesta, es necesario aplicar una serie de test estadísticos: En primer lugar, el test de Shapiro-Wilk (\cite{sw}) para comprobar la normalidad de las muestras, en este caso, de los resultados de la precisión. Si las muestras son normales, se aplica el test paramétrico t-test para ver si existen diferencias estadísticamente significativas o no. Si no lo son, es necesario calcular la media de cada muestra para ver cuál es mayor. En el caso de no normalidad, debemos acudir a un test no paramétrico, como es el de Test U de Mann-Whitney (\cite{umw}) para comprobar la diferencia entre las muestras. Si, siendo diferentes, alguna de ellas (o ambas) no siguen una distribución normal, calculamos la mediana en vez de la media para hacer la comparación. Para hacer todos estos cálculos, de aquí en adelante utilizo la siguiente función:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.45]{comparaAl.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Método para comparar el rendimiento de dos algoritmos} 
	\label{fig:compAl}
\end{figure}

En concreto, para HoeffdingTree Adaptativo (HA) y HoeffdingTree no adaptativo (HNA), obtenemos que

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.35]{off1.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Test de Shapiro-Wilk sobre HA y HNA} 
	\label{fig:off4}
\end{figure}
 
la población de resultados de precisión para el algoritmo Hoeffding Tree adaptativo sigue una distribución normal (p-valor 0.3757... > 0.05) a diferencia de Hoeffding Tree no adaptativo, (p-valor 8.3028...e-07 < 0.05, rechazando la hipótesis de normalidad). Por tanto, es necesario utilizar el test no paramétrico (ya que no se cumplen las hipótesis para los paramétricos) para comparar el rendimiento de los clasificadores. 

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{off2.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Test U Mann Whitney y promedios para HA y HNA} 
	\label{fig:off5}
\end{figure}

Se obtiene un p-valor para el test de Mann-Whitney de 8.4048...e-05 < 0.05, por lo que se rechaza la hipótesis de que las distribuciones son iguales. Los promedios (HNA con mediana, HA con media) arrojan que el HNA es mejor que el HA, aunque la diferencia es bastante estrecha. 

\subsection{Entrenamiento online}

\subsubsection{Entrenamiento de un clasificador HoeffdingTree online (Interleaved Test-Then-Train) con generador WaveFormGenerator y varias semillas en entrenamiento. HoeffdingTree adaptativo}

En esta ocasión, ejecutamos un entrenamiento online con el método Interleaved Test-Then-Train y con generado WaveFormGenerator para los clasificadores HoeffdingTree y HoeffdingTree adaptativo. Para ello, hacemos 30 ejecuciones con semillas distintas para generar una población de resultados y comparar los resultados:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{onl1.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Entrenamiento online para HA y HNA} 
	\label{fig:onl1}
\end{figure}

Recogemos los resultados en la siguiente tabla:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{onl-res.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resultados del Entrenamiento online para HA y HNA} 
	\label{fig:onl2}
\end{figure}

\subsubsection{¿Cree que algún clasificador es significativamente mejor que el otro?}

De nuevo vemos que los resultados en accuracy son parejos, todos alrededor de un 83\%. Sin embargo, realizo un estudio más detenido basado en test estadísticos. Primero, para poder aplicar un test que compare las dos muestras, debemos comprobar si son normales o no a través del test de Shapiro-Wilk:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{onl3.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Shapiro-Wilk sobre Entrenamiento online para HA y HNA} 
	\label{fig:onl3}
\end{figure}

Como ambos p-valores son mayores que 0.05, no podemos rechazar la hipótesis de normalidad, luego la asumimos. Siendo así, es posible aplicar un test paramétrico, por lo que utilizo el t-test:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{onl4.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{t-test y promedios para HA y HNA} 
	\label{fig:onl4}
\end{figure}

El p-valor del t-test es menor que 0.05, por lo que rechazamos la hipótesis de que las distribuciones sean iguales y, como ambas son normales, calculamos el promedio vía la media, obteniendo que HoeffdingTree Adaptativo tiene un mejor rendimiento.

\subsection{Entrenamiento online en datos con concept drift}

Para el entrenamiento online, sobre el método InterleavedTestThenTrain, con HoeffdingTree y la configuración indicada del generador RandomRBFGeneratorDrift, un algoritmo que genera un flujo con con cambio basado en funciones aleatorias de base radial, de forma que el cambio de concepto se introduce moviendo los centroides a velocidad constante (\cite{moa-manual}). Planteo la siguiente orden en la interfaz gráfica de MOA:

\textit{EvaluateInterleavedTestThenTrain -l trees.HoeffdingTree -s (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000}

siendo s la velocidad de cambio de los centroides en el modelo, k el número de centroides con drift, a el número de atributos, n el número de centroides, c número de clases (por defecto 2), i la semilla para la generación de instancias y r la semilla para la generación del modelo (por defecto 1 ambas). En consecuencia, se obtienen los siguientes resultados, primero la gráfica de la precisión y luego los estadísticos:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{cd1.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Gráfica de precisión en la clasificación respecto al número de instancias} 
	\label{fig:cd1}
\end{figure}

Vemos en la gráfica que el rendimiento va decayendo lentamente conforme aumenta el número de instancias. Si observamos los valores estadísticos

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{cd2.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Medidas de rendimiento del modelo} 
	\label{fig:cd2}
\end{figure}

obtenemos un 80.86\% de accuracy y un Kappa de 61.65.

Pasamos ahora al clasificador HoeffdingTree adaptativo:

\textit{EvaluateInterleavedTestThenTrain -l trees.HoeffdingAdaptiveTree -s \\ (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000}

Presentamos a continuación los resultados de curva de acierto:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{cd3.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Gráfica de precisión en la clasificación respecto al número de instancias} 
	\label{fig:cd3}
\end{figure}

Si bien es cierto que los tests estadísticos en las secciones anteriores nos han indicado que se encontraban diferencias entre HoeffdingTree y HoeffdingAdaptiveTree, el rendimiento era prácticamente parejo. Podríamos extraer la idea de que, si no hay cambio de concepto, un clasificador y su versión adaptativa no tienen apenas diferencias. Esta es la primera vez en la que vemos la mejoría de la adaptación respecto del algoritmo original, habida cuenta de que este último iba empeorando su rendimiento conforme se introducían los nuevos datos y, sin embargo, el adaptativo obtiene un resultado estable y, además, muy bueno. Lo confirmamos con la tabla de medidas:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{cd4.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Medidas de rendimiento del algoritmo HoeffdingAdaptiveTree} 
	\label{fig:cd4}
\end{figure}

viendo que, verdaderamente, hay diferencias significativas. Lo confirmamos a continuación con un estudio estadístico, modificando las semillas. Generamos 30 ejecuciones por algoritmos, obteniendo el siguiente resultado:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{cd5.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Tests estadísticos para comparar los clasificadores} 
	\label{fig:cd5}
\end{figure}

Vemos que los resultados provenientes del clasificador HoeffdingTree no son siguen una distribución normal, mientras que el adaptativo sí, por lo que aplicamos un test no paramétrico y vemos que se rechaza la hipótesis de que los algoritmos sean iguales, viéndose que, claramente, hay diferencias significativas en favor del HoeffdingAdaptiveTree.

\subsection{Entrenamiento online en datos con concept drift, incluyendo mecanismos para olvidar instancias pasadas}

Para conseguir que se olviden instancias pasadas y se base en las nuevas, sustituyo EvaluateInterleavedTestThenTrain por EvaluatePrequential y añado el tamaño de la ventana. Primero, lo ejecutamos para el clasificador adaptativo con la siguiente sentencia

\textit{EvaluatePrequential -l trees.HoeffdingAdaptiveTree -s (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000 -w 1000}

obteniendo esta gráfica

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{graph4.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{HoeffdingTree Adaptativo olvidando instancias pasadas} 
	\label{fig:graph4}
\end{figure}

y las siguientes medidas 

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{measures41.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resultados para HoeffdingTree Adaptativo olvidando instancias pasadas} 
	\label{fig:measure41}
\end{figure}

mejorando aún más los resultados que en el ConceptDrift anterior, ya que se va adaptando muy bien a los nuevos conceptos, dejando atrás los anteriores. Si ahora nos centramos en el HoeffdingTree

\textit{EvaluatePrequential -l trees.HoeffdingTree -s (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000 -w 1000}

vemos a través de su gráfica y sus medidas que los resultados no son tan buenos:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{graph42.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{HoeffdingTree olvidando instancias pasadas} 
	\label{fig:graph42}
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{measures42.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resultados para HoeffdingTree  olvidando instancias pasadas} 
	\label{fig:measure42}
\end{figure}

Vemos en la gráfica que, para cada cambio de concepto, el clasificador tiene una bajada en rendimiento y vuelve a subir, pero desde luego los resultados son los peores hasta el momento. El motivo es que, como el algoritmo no es adaptativo, siempre tiene en cuenta todas las instancias que le llegaron hasta el momento. Como la generación está basada en cambio de concepto con olvido, cada vez que se introduce uno nuevo el rendimiento del clasificador cae en picado hasta que consigue introducir ese concepto, acoplado a los anteriores, por lo que el rendimiento vuelve a mejorar hasta que se introduce el nuevo concepto.

Tras 30 ejecuciones con semillas distintas, siguiendo la misma metodología que en las anteriores secciones, obtenemos los siguientes resultados:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{test4.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Diferencias significativas entre los clasificadores} 
	\label{fig:test4}
\end{figure}

Como se puede ver, según el test U de Mann-Whitney, rechazamos la hipótesis de que los clasificadores sean equivalentes, por lo que hay diferencias significativas a favor del HoeffdingAdaptiveTree.

\subsection{Entrenamiento online en datos con concept drift, incluyendo mecanismos para reiniciar modelos tras la detección de cambios de concepto}

Empezamos esta última sección entrenando el clasificador HoeffdingTree con DDM mediante la siguiente orden:

\textit{EvaluateInterleavedTestThenTrain -l (moa.classifiers.drift.SingleClassifierDrift -l trees.HoeffdingTree -d DDM) -s (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000}

Al ejecutarla en la interfaz de MOA, encontramos en su gráfica que el rendimiento es muy estable y en torno al 97\% en precisión.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{graph51.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Curva de rendimiento para HoeffdingTree con DDM} 
	\label{fig:graph51}
\end{figure}

Lo confirmamos en la tabla de medidas, con un accuracy medio del 97.3\% y un estadístico Kappa 94.60:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{measures51.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Medidas de rendimiento para HoeffdingTree con DDM} 
	\label{fig:measure51}
\end{figure}


Pasamos ahora al clasificador HoeffdingAdaptiveTree, que ejecuto con la siguiente orden:

\textit{EvaluateInterleavedTestThenTrain -l (moa.classifiers.drift.SingleClassifierDrift -l \\ trees.HoeffdingAdaptiveTree -d DDM) -s (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000}

Como vemos en su gráfica y en la tabla de resultados, el rendimiento es algo menor pero igualmente estable conforme se van  añadiendo nuevos datos. Ninguno de los clasificadores se ve afectado por los cambios de concepto.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{graph52.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Curva de rendimiento para HoeffdingAdaptiveTree con DDM} 
	\label{fig:graph52}
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{measures52.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Medidas de rendimiento para HoeffdingAdaptiveTree con DDM} 
	\label{fig:measure52}
\end{figure}

Como los resultados han sido muy similares, evaluamos estadísticamente si hay diferencias significativas. Para ello, procedo de la misma manera que en las secciones anteriores. Como se verá, el test U de Mann-Whitney nos arroja un p-valor de 
0.32602181120031787 > 0.05, por lo que no podemos rechazar la hipótesis de que las dos poblaciones de resultados, fruto de 30 ejecuciones con semillas distintas, sean iguales. En este caso, ambos algoritmos tienen un rendimiento sin diferencias significativas.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{test5.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Test de diferencias con DDM} 
	\label{fig:test5}
\end{figure}

\subsubsection{¿Qué diferencias se producen entre los métodos de los apartados 2.3,2.4 y 2.5?}

En los apartados 2.3, 2.4 y 2.5 mantenemos un esquema común de clasificadores (HoeffdingTree y HoeffdingAdaptiveTree) y de generador (RBFGeneratorDrift) que es el que introduce el cambio de concepto. Lo que se varía entre el apartado 2.3 y 2.4 es la forma de evaluar el flujo de datos en la clasificación. En 2.3 se utiliza InterleavedTestThenTrain para evaluar, en el que se utilizan todos los ejemplos vistos hasta el presente para calcular la precisión. Como contábamos con un modelo que no se adaptaba a cambios de concepto y otro que sí, al tener en cuenta todos los datos en la evaluación, HoeffdingTree iba empeorando su rendimiento conforme se introducían nuevos ejemplos. HoeffdingAdaptiveTree, por su parte, era capaz de mantener una precisión muy alta a pesar de los nuevos conceptos. Sin embargo, en 2.4 se introduce el factor de olvido de la mano de Prequential, que considera sólo los ejemplos más recientes para calcular la presión por medio de una ventana deslizante o factor de decaimiento (1000 en nuestro caso).  Sea $\alpha$ dicho factor de decaimiento. Entonces:

$$E_i = \frac{S_i}{B_i}$$
con
$$S_i = L_i + \alpha S_{i-1}$$
$$B_i = n_i + \alpha B_{i-1}$$
siendo $n_i$ el número de ejemplos utilizados para calcular la función de pérdida $L_i$. (\cite{moa-manual}).


Vemos como, de nuevo, HoeffdingAdaptiveTree es capaz de mantener el rendimiento aunque con pequeños vaivenes fruto del cambio en las evaluaciones del modelo. Sin embargo, vemos claramente como HoeffdingTree no es lo suficientemente robusto para mantener la precisión, de forma que va perdiendo y ganando accuracy, ya que la ventana deslizante hace que los aciertos que hizo en el pasado se vayan olvidando.

En 2.5 volvemos a evaluar con InterleavedTestThenTrain pero introduciendo el modelo por un clasificador simple, en el que se utiliza un método de detección de cambio (DDM (\cite{ddm})) que controla el número de errores producidos por el modelo de aprendizaje durante la predicción. Compara las estadísticas de dos ventanas: la primera contiene todos los datos y la segunda sólo los datos desde el principio hasta que el número de errores aumenta. Se considera que el número de errores en una muestra se modela a través de una distribución binomial. Un aumento significante en el error del algoritmo sugiere que la distribución de la clase está cambiando y, por tanto, el modelo actual es inapropiado. Definen un nivel de precaución y un nivel de cambio que se van evaluando y se actúa en consecuencia. Se actúa de la siguiente manera (\cite{moa-manual}, \cite{ddm}). Para cada punto $i$ de la muestra, el error es la probabilidad de clasificación errónea $p_i$, con una desviación estándar dada por $s_i = \sqrt{p_i (1-p_i)/i}$. Se almacenan los valores de $p_i$ y $s_i$ cuando $p_i+s_i$ alcanza su mínimo valor durante el proceso ($p_{min}$ y $s_{min}$). A partir de ese momento,

\begin{itemize}
	\item Nivel de precaución: $p_i + s_i \geq p_{min} + 2 s_{min}$
	\item Nivel de cambio: $p_i + s_i \geq p_{min} + 3 s_{min}$
\end{itemize} 

Es, por tanto, un clasificador que es capaz de lidiar con los cambios en los flujos, por lo que la clave que diferenciaba a HoeffdingTree y HoeffdingAdaptiveTree se pierde y, efectivamente, el test estadístico nos muestra que no hay diferencias significativas entre ellos. 
\newpage
\section{Bibliografía}

%------------------------------------------------

\bibliography{citas} %archivo citas.bib que contiene las entradas 
\bibliographystyle{plain} % hay varias formas de citar

\end{document}
