\input{preambuloSimple.tex}
\graphicspath{ {./images/} }
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{soul}


%----------------------------------------------------------------------------------------
%	TÍTULO Y DATOS DEL ALUMNO
%----------------------------------------------------------------------------------------

\title{	
\normalfont \normalsize 
\textsc{\textbf{Series Temporales y Minería de Flujos de Datos (2019-2020)} \\ Máster Oficial Universitario en Ciencia de Datos e Ingeniería de Computadores \\ Universidad de Granada} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Minería de Flujos de Datos. Trabajo Autónomo \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Luis Balderas Ruiz \\ \texttt{DNI:77145416N. luisbalderas@correo.ugr.es}} 
 % Nombre y apellidos 


\date{\normalsize\today} % Incluye la fecha actual

%----------------------------------------------------------------------------------------
% DOCUMENTO
%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Muestra el Título

\newpage %inserta un salto de página

\tableofcontents % para generar el índice de contenidos

\listoffigures

\listoftables

\newpage

%
%\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
%	\centering
%	\includegraphics[scale=0.6]{e1.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
%	\caption{Progresión de la imagen de E en cada iteración} 
%	\label{fig:e1}
%\end{figure}


\section{Teoría}

\subsection{Cuestionario}
\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.65]{cuestionario.jpg}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Cuestionario de teoría} 
	\label{cuestionario}
\end{figure}
\subsection{Problema de clasificación}

\subsection{Concept Drift}

\newpage
\section{Prácticas}

\subsection{Entrenamiento offline y evaluación posterior}

\subsubsection{Entrenamiento de un clasificador HoeffdingTree estacionario con generador WaveFormGenerator y varias semillas en entrenamiento. HoeffdingTree adaptativo}

Para enfrentar este problema, escribo un pequeño script con la ejecución en línea de órdenes de las sentencias necesarias para evaluar y entrenar un clasificador HoeffdingTree estacionario en primer lugar, y luego un HoeffdingTree adaptativo, que usa ADWIN para monitorizar el rendimiento de las ramas del árbol y las reemplaza por nuevas ramas cuando su precisión decrece y la de la nueva rama es superior (\cite{HA}). Se hacen 30 ejecuciones por cada experimento propuesto, variando la semilla de entrenamiento entre 4 y 34

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{off-code.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Código para la ejecución del Entrenamiento offline} 
	\label{fig:off1}
\end{figure}

Como resultado, al ejecutar la siguiente función, se genera un archivo que almacena los resultados de la precisión en clasificación y del estadístico Kappa:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{off-ev.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Extracción de resultados en el Entrenamiento offline} 
	\label{fig:off2}
\end{figure}

dando lugar a la siguiente tabla de datos:
\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.45]{ejercicio-offline.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resultados de la precisión en clasificación y estadístico Kappa para Entrenamiento offline} 
	\label{fig:off3}
\end{figure}

\subsubsection{¿Cree que algún clasificador es significativamente mejor que el otro?}

A priori, revisando la tabla de resultados, no parece haber gran diferencia entre los dos clasificadores. Sin embargo, para asegurar la respuesta, es necesario aplicar una serie de test estadísticos: En primer lugar, el test de Shapiro-Wilk (\cite{sw}) para comprobar la normalidad de las muestras, en este caso, de los resultados de la precisión. Si las muestras son normales, se aplica el test paramétrico t-test para ver si existen diferencias estadísticamente significativas o no. Si no lo son, es necesario calcular la media de cada muestra para ver cuál es mayor. En el caso de no normalidad, debemos acudir a un test no paramétrico, como es el de Test U de Mann-Whitney (\cite{umw}) para comprobar la diferencia entre las muestras. Si, siendo diferentes, alguna de ellas (o ambas) no siguen una distribución normal, calculamos la mediana en vez de la media para hacer la comparación. Para hacer todos estos cálculos, de aquí en adelante utilizo la siguiente función:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.45]{comparaAl.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Método para comparar el rendimiento de dos algoritmos} 
	\label{fig:compAl}
\end{figure}

En concreto, para HoeffdingTree Adaptativo (HA) y HoeffdingTree no adaptativo (HNA), obtenemos que

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.35]{off1.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Test de Shapiro-Wilk sobre HA y HNA} 
	\label{fig:off4}
\end{figure}
 
la población de resultados de precisión para el algoritmo Hoeffding Tree adaptativo sigue una distribución normal (p-valor 0.3757... > 0.05) a diferencia de Hoeffding Tree no adaptativo, (p-valor 8.3028...e-07 < 0.05, rechazando la hipótesis de normalidad). Por tanto, es necesario utilizar el test no paramétrico (ya que no se cumplen las hipótesis para los paramétricos) para comparar el rendimiento de los clasificadores. 

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{off2.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Test U Mann Whitney y promedios para HA y HNA} 
	\label{fig:off5}
\end{figure}

Se obtiene un p-valor para el test de Mann-Whitney de 8.4048...e-05 < 0.05, por lo que se rechaza la hipótesis de que las distribuciones son iguales. Los promedios (HNA con mediana, HA con media) arrojan que el HNA es mejor que el HA, aunque la diferencia es bastante estrecha. 

\subsection{Entrenamiento online}

\subsubsection{Entrenamiento de un clasificador HoeffdingTree online (Interleaved Test-Then-Train) con generador WaveFormGenerator y varias semillas en entrenamiento. HoeffdingTree adaptativo}

En esta ocasión, ejecutamos un entrenamiento online con el método Interleaved Test-Then-Train y con generado WaveFormGenerator para los clasificadores HoeffdingTree y HoeffdingTree adaptativo. Para ello, hacemos 30 ejecuciones con semillas distintas para generar una población de resultados y comparar los resultados:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{onl1.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Entrenamiento online para HA y HNA} 
	\label{fig:onl1}
\end{figure}

Recogemos los resultados en la siguiente tabla:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{onl-res.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resultados del Entrenamiento online para HA y HNA} 
	\label{fig:onl2}
\end{figure}

\subsubsection{¿Cree que algún clasificador es significativamente mejor que el otro?}

De nuevo vemos que los resultados en accuracy son parejos, todos alrededor de un 83\%. Sin embargo, realizo un estudio más detenido basado en test estadísticos. Primero, para poder aplicar un test que compare las dos muestras, debemos comprobar si son normales o no a través del test de Shapiro-Wilk:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{onl3.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Shapiro-Wilk sobre Entrenamiento online para HA y HNA} 
	\label{fig:onl3}
\end{figure}

Como ambos p-valores son mayores que 0.05, no podemos rechazar la hipótesis de normalidad, luego la asumimos. Siendo así, es posible aplicar un test paramétrico, por lo que utilizo el t-test:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{onl4.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{t-test y promedios para HA y HNA} 
	\label{fig:onl4}
\end{figure}

El p-valor del t-test es menor que 0.05, por lo que rechazamos la hipótesis de que las distribuciones sean iguales y, como ambas son normales, calculamos el promedio vía la media, obteniendo que HoeffdingTree Adaptativo tiene un mejor rendimiento.

\subsection{Entrenamiento online en datos con concept drift}

Para el entrenamiento online, sobre el método InterleavedTestThenTrain, con HoeffdingTree y la configuración indicada del generador RandomRBFGeneratorDrift, un algoritmo que genera un flujo con con cambio basado en funciones aleatorias de base radial, de forma que el cambio de concepto se introduce moviendo los centroides a velocidad constante (\cite{moa-manual}). Planteo la siguiente orden en la interfaz gráfica de MOA:

\textit{EvaluateInterleavedTestThenTrain -l trees.HoeffdingTree -s (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000}

siendo s la velocidad de cambio de los centroides en el modelo, k el número de centroides con drift, a el número de atributos, n el número de centroides, c número de clases (por defecto 2), i la semilla para la generación de instancias y r la semilla para la generación del modelo (por defecto 1 ambas). En consecuencia, se obtienen los siguientes resultados, primero la gráfica de la precisión y luego los estadísticos:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{cd1.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Gráfica de precisión en la clasificación respecto al número de instancias} 
	\label{fig:cd1}
\end{figure}

Vemos en la gráfica que el rendimiento va decayendo lentamente conforme aumenta el número de instancias. Si observamos los valores estadísticos

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{cd2.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Medidas de rendimiento del modelo} 
	\label{fig:cd2}
\end{figure}

obtenemos un 80.86\% de accuracy y un Kappa de 61.65.

Pasamos ahora al clasificador HoeffdingTree adaptativo:

\textit{EvaluateInterleavedTestThenTrain -l trees.HoeffdingAdaptiveTree -s \\ (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000}

Presentamos a continuación los resultados de curva de acierto:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{cd3.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Gráfica de precisión en la clasificación respecto al número de instancias} 
	\label{fig:cd3}
\end{figure}

Si bien es cierto que los tests estadísticos en las secciones anteriores nos han indicado que se encontraban diferencias entre HoeffdingTree y HoeffdingAdaptiveTree, el rendimiento era prácticamente parejo. Podríamos extraer la idea de que, si no hay cambio de concepto, un clasificador y su versión adaptativa no tienen apenas diferencias. Esta es la primera vez en la que vemos la mejoría de la adaptación respecto del algoritmo original, habida cuenta de que este último iba empeorando su rendimiento conforme se introducían los nuevos datos y, sin embargo, el adaptativo obtiene un resultado estable y, además, muy bueno. Lo confirmamos con la tabla de medidas:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{cd4.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Medidas de rendimiento del algoritmo HoeffdingAdaptiveTree} 
	\label{fig:cd4}
\end{figure}

viendo que, verdaderamente, hay diferencias significativas. Lo confirmamos a continuación con un estudio estadístico, modificando las semillas. Generamos 30 ejecuciones por algoritmos, obteniendo el siguiente resultado:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{cd5.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Tests estadísticos para comparar los clasificadores} 
	\label{fig:cd5}
\end{figure}

Vemos que los resultados provenientes del clasificador HoeffdingTree no son siguen una distribución normal, mientras que el adaptativo sí, por lo que aplicamos un test no paramétrico y vemos que se rechaza la hipótesis de que los algoritmos sean iguales, viéndose que, claramente, hay diferencias significativas en favor del HoeffdingAdaptiveTree.

\subsection{Entrenamiento online en datos con concept drift, incluyendo mecanismos para olvidar instancias pasadas}

Para conseguir que se olviden instancias pasadas y se base en las nuevas, sustituyo EvaluateInterleavedTestThenTrain por EvaluatePrequential y añado el tamaño de la ventana. Primero, lo ejecutamos para el clasificador adaptativo con la siguiente sentencia

\textit{EvaluatePrequential -l trees.HoeffdingAdaptiveTree -s (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000 -w 1000}

obteniendo esta gráfica

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{graph4.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{HoeffdingTree Adaptativo olvidando instancias pasadas} 
	\label{fig:graph4}
\end{figure}

y las siguientes medidas 

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{measures41.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resultados para HoeffdingTree Adaptativo olvidando instancias pasadas} 
	\label{fig:measure41}
\end{figure}

mejorando aún más los resultados que en el ConceptDrift anterior, ya que se va adaptando muy bien a los nuevos conceptos, dejando atrás los anteriores. Si ahora nos centramos en el HoeffdingTree

\textit{EvaluatePrequential -l trees.HoeffdingTree -s (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000 -w 1000}

vemos a través de su gráfica y sus medidas que los resultados no son tan buenos:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{graph42.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{HoeffdingTree olvidando instancias pasadas} 
	\label{fig:graph42}
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{measures42.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resultados para HoeffdingTree  olvidando instancias pasadas} 
	\label{fig:measure42}
\end{figure}

Vemos en la gráfica que, para cada cambio de concepto, el clasificador tiene una bajada en rendimiento y vuelve a subir, pero desde luego los resultados son los peores hasta el momento. El motivo es que, como el algoritmo no es adaptativo, siempre tiene en cuenta todas las instancias que le llegaron hasta el momento. Como la generación está basada en cambio de concepto con olvido, cada vez que se introduce uno nuevo el rendimiento del clasificador cae en picado hasta que consigue introducir ese concepto, acoplado a los anteriores, por lo que el rendimiento vuelve a mejorar hasta que se introduce el nuevo concepto.

Tras 30 ejecuciones con semillas distintas, siguiendo la misma metodología que en las anteriores secciones, obtenemos los siguientes resultados:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{test4.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Diferencias significativas entre los clasificadores} 
	\label{fig:test4}
\end{figure}

Como se puede ver, según el test U de Mann-Whitney, rechazamos la hipótesis de que los clasificadores sean equivalentes, por lo que hay diferencias significativas a favor del HoeffdingAdaptiveTree.

\subsection{Entrenamiento online en datos con concept drift, incluyendo mecanismos para reiniciar modelos tras la detección de cambios de concepto}

Empezamos esta última sección entrenando el clasificador HoeffdingTree con DDM mediante la siguiente orden:

\textit{EvaluateInterleavedTestThenTrain -l (moa.classifiers.drift.SingleClassifierDrift -l trees.HoeffdingTree -d DDM) -s (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000}

Al ejecutarla en la interfaz de MOA, encontramos en su gráfica que el rendimiento es muy estable y en torno al 97\% en precisión.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{graph51.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Curva de rendimiento para HoeffdingTree con DDM} 
	\label{fig:graph51}
\end{figure}

Lo confirmamos en la tabla de medidas, con un accuracy medio del 97.3\% y un estadístico Kappa 94.60:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{measures51.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Medidas de rendimiento para HoeffdingTree con DDM} 
	\label{fig:measure51}
\end{figure}


Pasamos ahora al clasificador HoeffdingAdaptiveTree, que ejecuto con la siguiente orden:

\textit{EvaluateInterleavedTestThenTrain -l (moa.classifiers.drift.SingleClassifierDrift -l \\ trees.HoeffdingAdaptiveTree -d DDM) -s (generators.RandomRBFGeneratorDrift -s 0.001 -k 3 -a 7 -n 3) -i 2000000}

Como vemos en su gráfica y en la tabla de resultados, el rendimiento es algo menor pero igualmente estable conforme se van  añadiendo nuevos datos. Ninguno de los clasificadores se ve afectado por los cambios de concepto.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{graph52.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Curva de rendimiento para HoeffdingAdaptiveTree con DDM} 
	\label{fig:graph52}
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{measures52.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Medidas de rendimiento para HoeffdingAdaptiveTree con DDM} 
	\label{fig:measure52}
\end{figure}

Como los resultados han sido muy similares, evaluamos estadísticamente si hay diferencias significativas. Para ello, procedo de la misma manera que en las secciones anteriores. Como se verá, el test U de Mann-Whitney nos arroja un p-valor de 
0.32602181120031787 > 0.05, por lo que no podemos rechazar la hipótesis de que las dos poblaciones de resultados, fruto de 30 ejecuciones con semillas distintas, sean iguales. En este caso, ambos algoritmos tienen un rendimiento sin diferencias significativas.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{test5.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Test de diferencias con DDM} 
	\label{fig:test5}
\end{figure}

\subsubsection{¿Qué diferencias se producen entre los métodos de los apartados 2.3,2.4 y 2.5?}

En los apartados 2.3, 2.4 y 2.5 mantenemos un esquema común de clasificadores (HoeffdingTree y HoeffdingAdaptiveTree) y de generador (RBFGeneratorDrift) que es el que introduce el cambio de concepto. Lo que se varía entre el apartado 2.3 y 2.4 es la forma de evaluar el flujo de datos en la clasificación. En 2.3 se utiliza InterleavedTestThenTrain para evaluar, en el que se utilizan todos los ejemplos vistos hasta el presente para calcular la precisión. Como contábamos con un modelo que no se adaptaba a cambios de concepto y otro que sí, al tener en cuenta todos los datos en la evaluación, HoeffdingTree iba empeorando su rendimiento conforme se introducían nuevos ejemplos. HoeffdingAdaptiveTree, por su parte, era capaz de mantener una precisión muy alta a pesar de los nuevos conceptos. Sin embargo, en 2.4 se introduce el factor de olvido de la mano de Prequential, que considera sólo los ejemplos más recientes para calcular la presión por medio de una ventana deslizante o factor de decaimiento (1000 en nuestro caso).  Sea $\alpha$ dicho factor de decaimiento. Entonces:

$$E_i = \frac{S_i}{B_i}$$
con
$$S_i = L_i + \alpha S_{i-1}$$
$$B_i = n_i + \alpha B_{i-1}$$
siendo $n_i$ el número de ejemplos utilizados para calcular la función de pérdida $L_i$. (\cite{moa-manual}).


Vemos como, de nuevo, HoeffdingAdaptiveTree es capaz de mantener el rendimiento aunque con pequeños vaivenes fruto del cambio en las evaluaciones del modelo. Sin embargo, vemos claramente como HoeffdingTree no es lo suficientemente robusto para mantener la precisión, de forma que va perdiendo y ganando accuracy, ya que la ventana deslizante hace que los aciertos que hizo en el pasado se vayan olvidando.

En 2.5 volvemos a evaluar con InterleavedTestThenTrain pero introduciendo el modelo por un clasificador simple, en el que se utiliza un método de detección de cambio (DDM (\cite{ddm})) que controla el número de errores producidos por el modelo de aprendizaje durante la predicción. Compara las estadísticas de dos ventanas: la primera contiene todos los datos y la segunda sólo los datos desde el principio hasta que el número de errores aumenta. Se considera que el número de errores en una muestra se modela a través de una distribución binomial. Un aumento significante en el error del algoritmo sugiere que la distribución de la clase está cambiando y, por tanto, el modelo actual es inapropiado. Definen un nivel de precaución y un nivel de cambio que se van evaluando y se actúa en consecuencia. Se actúa de la siguiente manera (\cite{moa-manual}, \cite{ddm}). Para cada punto $i$ de la muestra, el error es la probabilidad de clasificación errónea $p_i$, con una desviación estándar dada por $s_i = \sqrt{p_i (1-p_i)/i}$. Se almacenan los valores de $p_i$ y $s_i$ cuando $p_i+s_i$ alcanza su mínimo valor durante el proceso ($p_{min}$ y $s_{min}$). A partir de ese momento,

\begin{itemize}
	\item Nivel de precaución: $p_i + s_i \geq p_{min} + 2 s_{min}$
	\item Nivel de cambio: $p_i + s_i \geq p_{min} + 3 s_{min}$
\end{itemize} 

Es, por tanto, un clasificador que es capaz de lidiar con los cambios en los flujos, por lo que la clave que diferenciaba a HoeffdingTree y HoeffdingAdaptiveTree se pierde y, efectivamente, el test estadístico nos muestra que no hay diferencias significativas entre ellos. 
\newpage
\section{Bibliografía}

%------------------------------------------------

\bibliography{citas} %archivo citas.bib que contiene las entradas 
\bibliographystyle{plain} % hay varias formas de citar

\end{document}
