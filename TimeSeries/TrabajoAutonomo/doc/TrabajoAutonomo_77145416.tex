\input{preambuloSimple.tex}
\graphicspath{ {./images/} }
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{soul}


%----------------------------------------------------------------------------------------
%	TÍTULO Y DATOS DEL ALUMNO
%----------------------------------------------------------------------------------------

\title{	
\normalfont \normalsize 
\textsc{\textbf{Series Temporales y Minería de Flujo de Datos (2019-2020)} \\ Máster Oficial Universitario en Ciencia de Datos e Ingeniería de Computadores \\ Universidad de Granada} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Trabajo autónomo I: Series Temporales \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Luis Balderas Ruiz \\ \texttt{luisbalderas@correo.ugr.es}} 
 % Nombre y apellidos 


\date{\normalsize\today} % Incluye la fecha actual

%----------------------------------------------------------------------------------------
% DOCUMENTO
%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Muestra el Título

\newpage %inserta un salto de página

\tableofcontents % para generar el índice de contenidos

\listoffigures


\newpage

%
%\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
%	\centering
%	\includegraphics[scale=0.6]{e1.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
%	\caption{Progresión de la imagen de E en cada iteración} 
%	\label{fig:e1}
%\end{figure}

\section{PARTE TEÓRICA}

\subsection{Introducción}

En la presente sección se justifican, desde un punto de vista teórico, las distintas decisiones tomadas para estudiar la Estación 2870, correspondiente a Salamanca, para acabar haciendo predicciones a nivel diario (los siete primeros días de marzo de 2018) y mensual (marzo y abril de 2018) sobre la temperatura máxima registrada en dicha estación. 

\subsection{Preprocesamiento}

El preprocesamiento es una de las partes más importantes en el proceso de adquisición de conocimiento. Bien conocidas son las gráficas que indican que la mayoría del tiempo invertido por los científicos de datos se emplea en limpiar y preparar los datos (\cite{prep-time}), así como proverbios como 'Garbage in, garbage out' (\cite{gigo}). En series temporales, esto no es una excepción. Tras la lectura de datos de la estación, que recogen diversas medidas atmosféricas diariamente, y la creación de nuevas características como Día y Mes, para así poder agrupar las instancias más cómodamente, estudio la correlación de las variables numéricas, que estudian las temperaturas máximas, mínimas y medias de cada día junto con velocidades de viento y nivel de precipitaciones:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{correlation.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Correlación de las variables con el target Temperatura máxima} 
	\label{fig:corr}
\end{figure}

Teniendo en cuenta que nuestro objetivo es modelar la temperatura máxima, la enfrentamos con el resto de variables, de manera que vemos que existe una alta correlación entre la temperatura máxima y la media (97\%) y la máxima y la mínima (83\%). Esto nos podría ser de ayuda para posteriores imputaciones de valores perdidos (que será la parte fundamental del preprocesamiento, debido a la alta cantidad de ellos). A continuación, estudio si existen anomalías en la temperatura máxima (vía el rango intercuartílico) con resultado negativo. Por tanto, me centro en la imputación de valores perdidos. En \cite{na1} encontramos distintos enfoques para tratar con \textit{missing values} en series temporales, desde ignorarlos, borrarlos, imputaciones con estadísticos como la media, mediana, moda; y otro más elaborados por medio de modelos autoregresivos, basados en algoritmos genéticos, interpolación, medidas de similaridad o clasificadores como SVM o kNN. Utilizo el paquete de R \textit{imputeTS} (\cite{RJ-2017-009}), especializado en imputación de series temporales univariables. En primer lugar, estudiamos la distribución de valores perdidos y la situamos temporalmente:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.42]{na-dist.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Distribución de valores perdidos en la serie temporal} 
	\label{fig:na-dist}
\end{figure}

viendo que una gran parte de datos perdidos se encuentra entre el periodo 4 y 5, es decir, en el año 2017. Más concretamente, vemos que en la franja temporal de entre el 67\% y el 75\% de tiempo se encuentra el 80\% de los valores perdidos.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.23]{nadistbar.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Distribución de valores perdidos en la serie temporal con lapso de tiempo} 
	\label{fig:na-distbar}
\end{figure}

Además, tras una exploración de datos, vemos que todas las mediciones de esos días están perdidas, probablemente por un avería del dispositivo. Esto nos hace descartar la posibilidad de imputar valores vía a las variables más correladas a la temperatura máxima. Tras el estudio de ciertas estadísticas más, pruebo varias funciones de imputación del paquete. Entre ellas, LOFC (imputación por la última observación considerada), NOFC, medias móviles, la imputación de modelo estructural y suavizado de Kalman,  Seadec (imputación basada en la descomposición de la estacionalidad) y Seasplit (imputación basada en la partición de la estacionalidad). Acabo adoptando esta última, porque visualmente parece la más acertada, ya que las otras imputan los valores de una forma muy lineal, lo que difiere del comportamiento normal de la serie, con cierta fluctuación y diente de sierra.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.24]{seasplit-na.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resultado de la imputación de valores perdidos con Seasplit} 
	\label{fig:seasplit}
\end{figure}

Tras imputar los valores perdidos, es momento de generar las series, diaria y mensual, que me servirá para modelar y predecir. En el caso de la diaria, tras varias pruebas tomando todos los días y estacionalidad de 365 días frustradas, decido tomar de cada año sólo el mes de febrero y marzo. Como queremos predecir los primeros siete días de marzo de 2018, creo que es la idea más acertada. \\

Respecto de la serie mensual, tras hacer pruebas con filtros gaussianos y de medias móviles, decido que el valor de la temperatura máxima para cada mes estará condicionada por la media de los datos de ese mes (en un 80\%) y el valor de temperatura máxima calculado para el mes anterior (en un 20\%). Intento así tener en cuenta en gran medida el periodo actual pero también el valor anterior, logrando más cohesión entre los valores de la serie. 

\subsection{Análisis de la tendencia y de estacionalidad}

Tal y como vemos en \cite{hyndman}, asumiendo una descomposición aditiva,  podemos tratar una serie temporal como

$$y_t =S_t + T_t + R_t$$

donde $y_t$ conforma los datos de la serie, $S_t$ la componente estacional, $T_t$ la tendencia y $R_t$ la parte aleatoria o de ruido, todas ellas en un periodo $t$. Podemos también definir una descomposición multiplicativa. Sin embargo, en este caso es más apropiada una descomposición aditiva, dado que ni las fluctuaciones en la estacionalidad ni la tendencia varían con el nivel de la serie temporal. Si fuera el caso, aplicaríamos un logaritmo para transformar el producto en suma de logaritmos, concurriendo al final en la misma metodología aditiva. Dado que la componente estacional y la tendencia, de existir, tienen un comportamiento que podemos entender, y por tanto cuantificar, la idea es restarlas en dicha descomposición aditiva para acabar teniendo solamente la parte aleatoria, que si intentaremos modelar con los algoritmos de aprendizaje de series, más concretamente, modelos ARIMA. 

Veamos primeramente el caso de la estación diaria. 

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.31]{decomp-diario.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Descomposición clásica de la serie temporal diaria} 
	\label{fig:decomp-diaria}
\end{figure}

Estudiando la tendencia, vemos que no tiene parecido a ninguna función conocida para realizar una aproximación funcional. Además, la variación es apenas de 2ºC, por lo que asumimos que la serie no tiene tendencia, por lo que forma parte del ruido. Respecto a la estacionalidad, fijo el periodo en 60, puesto que más o menos es el número de días que pasan desde un día hasta el mismo día en otro año (según la serie temporal generada solamente con los días de febrero y marzo de cada año). Por tanto, repito ese patrón de estacionalidad durante los distintos periodos y se lo resto a la serie, quedando así:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.25]{diaria-Sin-Est.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Serie sin estacionalidad (en rojo el conjunto de test)} 
	\label{fig:diaria-sinest}
\end{figure}

Si nos centramos en la serie de la estación mensual

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.31]{decom-mensual.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Descomposición clásica de la serie temporal mensual} 
	\label{fig:decom-mensual}
\end{figure}

Volvemos a encontrarnos un patrón similar en la tendencia, que vuelvo a asemejarla a ruido, y una estacionalidad muy clara que elimino con la misma metodología que en el caso diario, obteniendo

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.31]{trtsNE-mensual.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Serie sin estacionalidad (en rojo el conjunto de test)} 
	\label{fig:trtsNE-mensual}
\end{figure}

\subsection{Estacionariedad}

Una serie es estacionaria cuando sus propiedades no dependen del momento temporal en el que sea observada. Por tanto, una serie temporal con tendencia o estacionalidad no puede ser estacionaria, ya que la tendencia y la estacionalidad afectan al valor de la serie temporal en diferentes momentos (\cite{hyndman}) (por ese motivo pretendemos eliminar la estacionalidad y la tendencia en el apartado anterior). La estacionariedad se comprueba a través del test de Dickey-Fuller (\cite{df}), que mide si $\Phi = 0$ en
$$y_t = \alpha + \beta t + \Phi y_{t-1} +e_t$$
que se escribe como
$$\Delta y_t = y_t - y_{t-1} = \alpha + \beta t + \gamma y_{t-1} +e_t$$

siendo $y_t$ los datos de la serie. El test de Dickey-Fuller Aumentado permite procesos autoregresivos de orden superior incluyendo $\Delta y_{t-p}$ en el modelo. La hipótesis nula para ambos tests es que los datos son no estacionarios, por lo que se pretende obtener un p-valor menor que 0.05 para rechazarla. 

En el que caso de que no tengamos una serie estacionaria (no podemos rechazar la hipótesis nula, el gráfico ACF no tiende rápidamente a cero sino lentamente...) se puede emplear un método para hacerla estacionaria: la diferenciación. Ciertas transformaciones, como el logaritmo, ayudan a estabilizar la varianza en las series temporales. La diferenciación, por su parte, ayuda a estabilizar la media de la serie eliminando cambios, por lo que reduce tendencias o estacionalidades residuales. En el caso que nos ocupa, utilizo la diferenciación para suavizar la serie temporal y obtener unas gráficas ACF y PACF más claras para los modelos posteriores, a pesar de que en la estación diaria, antes de diferenciar, el test de Dickey-Fuller ya indica que la serie es estacionaria. 

\subsection{Modelado de series temporales}

\subsubsection{Modelos autoregresivos}

En un modelo de regresión multiple, predecimos la variable usando una combinación lineal de los predictores. En un modelo autoregresivo, predecimos la variable de interés usando una combinación lineal de los valores pasados de la variable (de ahí autoregresivo) (\cite{hyndman}). Por tanto, un modelo autoregresivo de orden $p$ se puede escribir como

$$y_t = c + \Phi_1 y_{t-1}+ \Phi_2 y_{t-2}+\dots+\Phi_p y_{t-p}+ \epsilon_t$$,

donde $\epsilon_t$ es ruido blanco. Nos referiremos a este tipo de modelos como $AR(p)$. Generalmente, restringimos los modelos autoregresivos a datos estacionarios, en cuyo caso se requieren ciertas condiciones sobre los parámetros:
\begin{itemize}
	\item $AR(1): -1 < \Phi_1 <1$.
	\item $AR(2): -1 < \Phi_2 <1, \Phi_1 +\Phi_2 < 1, \Phi_2-\Phi_1<1$
\end{itemize}

Para $p\geq 3$, las restricciones son mucho más severas (\cite{hyndman}).

\subsubsection{Modelos de medias móviles}

En lugar de utilizar los valores anteriores para predecir la variable deseada, un modelo de medias móviles utiliza los errores de predicción anteriores en un modelo de regresión:

$$y_t = c + \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \dots + \theta_q \epsilon_{t-q}$$

Téngase en cuenta que cada valor $y_t$ puede interpretarse como una media móvil ponderada de algunos errores de predicción anteriores.

\subsubsection{Modelos ARIMA en R}

Elegimos los parámetros del modelo ARIMA (AR o MA) estudiando las gráficas ACF y PACF. En el caso de un modelo AR, para elegir el parámetro, utilizamos el último valor distinto de 0 (que se sale de los márgenes y resulta representativo, siendo los otros ruido). En el caso del modelo MA, examinamos la gráfica ACF en busca del último valor más representativo. \\

Una vez entrenados los modelos, es necesario comprobar la bondad del ajuste, es decir, hay que evaluar la aleatoriedad de los residuos (Test de Box-Pierce) para comprobar si el modelo tiene sesgo; la normalidad de los residuos (Test de Jarque Bera y Shapiro-Wilk). Si no se comprueban las hipótesis mencionadas, los modelos no tienen un comportamiento correcto y no serán buenos predictores, por lo que deberían ser descartados. Además, para dos modelos que cumplan las hipótesis estadísticas, es necesario utilizar algún criterio para decidir cuál tiene mejor rendimiento. Para ello, utilizamos el error cuadrático medio sobre las instancias de test y el criterio de información de Akaike (\cite{aic}), que se basa en

$$ AIC = 2k + n\log(\frac{RSS}{n})$$
siendo $k$ el número de grados de libertad, $n$ el número de datos y $RSS$ la suma de los cuadrados de los residuos. 

\section{PARTE PRÁCTICA}

La estación elegida es la 2870, correspondiente a la ciudad de Salamanca. La parte de preprocesamiento, explicada en la sección correspondiente del apartado anterior, ha sido común para ambos enfoques (diario y mensual) y se ha basado mayoritariamente en utilizar la biblioteca \textit{imputeTS} y el algoritmo Seasplit con medias móviles para imputar los valores perdidos. Una vez hecho eso, la estación diaria está formada por los días de febrero y marzo de cada año que tenemos disponible (con fin de predecir los 7 primeros días de marzo de 2018) y la mensual, tiene en un cuenta, en un 80\%, la media de la temperatura máxima del mes actual y en un 20\% el valor calculado para el mes anterior. De esta forma, partimos de las series listas para ser analizadas. 

\subsection{Estación diaria}

La estación diaria, utilizando la descomposición clásica, se muestra como sigue:

 \begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
 	\centering
 	\includegraphics[scale=0.31]{decomp-diario.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
 	\caption{Descomposición clásica de la serie temporal diaria} 
 	\label{fig:decomp-diaria}
 \end{figure}

Como ya expliqué en la sección anterior, la tendencia no sigue una función conocida para ser aproximada y, además, no tiene un criterio fijo de crecimiento y el rango de valores en la que se mueve es pequeño (apenas un par de grados). Por tanto, considero que es ruido. Modelo la estacionalidad con un periodo de 60 días, de forma que, al restarlo tanto en entrenamiento y test (7 días), obtengo el siguiente resultado:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.25]{diaria-Sin-Est.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Serie sin estacionalidad (en rojo el conjunto de test)} 
	\label{fig:diaria-sinest2}
\end{figure}

Una vez eliminada la estacionalidad, es momento de estudiar la estacionariedad. A pesar de que el test de Dickey-Fuller aumentado da un valor de 0.01 < 0.05, por lo que se rechaza la hipótesis nula y la serie es estacionaria, la gráfica ACF 

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.25]{acf-diario.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Gráfica ACF de la serie diaria} 
	\label{fig:acf-diario}
\end{figure}

no converge rápidamente a cero y no ayuda para la búsqueda posterior de los parámetros de los modelos ARIMA. Por tanto, diferencio la serie en busca de valores más claros.
\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.25]{acf-diario-d.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Gráfica ACF de la serie diaria diferenciada} 
	\label{fig:acf-diario-d}
\end{figure}

Vemos que ahora sí la convergencia a cero es muy rápida y sí podemos extraer ciertos valores distintos de cero para los modelos ARIMA. Presenta también la gráfica PACF

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.25]{pacf-diario-d.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Gráfica PACF de la serie diaria diferenciada} 
	\label{fig:pacf-diario-d}
\end{figure}

Antes de proponer los modelos ARIMA para predicción, centramos la serie en el 0, ya que si no el algoritmo no funciona correctamente. Para ello, le resto a la serie su media. Las gráficas ACF y PACF nos dan ciertos candidatos a parámetros para los modelos autoregresivos y de medias móviles. En el caso de AR, el gráfico PACF nos brinda los valores de p=2 y p=7 (más claramente 7). Para MA, el gráfica ACF nos da los mismos, así que esos son los modelos que entreno. Como he llevado a cabo una diferenciación, en vez de integrar la serie, indico en el parámetro $d=1$ en la creación que hemos diferenciado una vez. Para examinar la bondad del ajuste \textit{per se}, utilizamos el test de Box-Pierce para la aleatoriedad de los residuos y Jarque-Bera y Shapiro-Wilk para la normalidad de los mismos. Sólo los modelos autoregresivos pasan los tests, por lo que son los candidatos a ser evaluados como predictores. Veamos la predicción del AR(7)

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.25]{ar710-diario.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Predicción en training y test para el modelo AR(7)} 
	\label{fig:ar710-d}
\end{figure}

y del AR(2)

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.25]{ar210-diario.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Predicción en training y test para el modelo AR(2)} 
	\label{fig:ar210-d}
\end{figure}

para training y test.\\

Pasamos ahora a decidir qué modelo es el que tiene mejor rendimiento para hacer la predicción. En primer lugar, calculo el error cuadrático medio en la predicción en training y test para cada uno de los modelos. En el caso de AR(7), el MSE vale 8.862888 y 55.84348 respectivamente. Para AR(2), 11.62977 Y 60.46596. Como se puede ver, el error es considerablemente mayor para AR(7). Sin embargo, para terminar de confirmar, utilizo el coeficiente AIC. El resultado nos muestra un valor de 1298.999 para AR(7) con 8 parámetros, mientras que para AR(2) obtenemos 3 parámetros libres y 1356.924. A pesar de que el modelo AR(7) es más complejo que AR(2), comete menos errores y el valor de AIC es menor, por lo que es el idóneo para hacer la predicción. \\

Una vez terminado el análisis, es momento de repetir todo el proceso sobre la serie completa y realizar la predicción. Por tanto, modelo la estacionalidad para la serie completa con 60 valores, centro la serie en el cero, genero el modelo AR(7), hago la predicción, y devuelvo los cambios, sumándole de nuevo la media y la estacionalidad. Gráficamente, el resultado de la predicción es el siguiente:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.25]{pred-diario1.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Predicción de los 7 primeros días de marzo (rojo)} 
	\label{fig:pred-diario1}
\end{figure}

Como el conjunto de datos es público y accesible, he descargado los valores correspondientes a los 7 días, incorporándolos al gráfico

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.25]{pred-diario2.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Predicción de los 7 primeros días de marzo (rojo) frente a valores reales (verde)} 
	\label{fig:pred-diario2}
\end{figure}

viendo que en los primeros días se acerca más pero que luego el resultado es muy dispar; y calculando el error cuadrático medio (37.56308) por lo que podemos extraer que el modelo ARIMA tiene un mal rendimiento para predicciones a un futuro ``lejano'', siendo más conveniente su uso en predicciones inmediatamente posteriores a los datos que tenemos.


\subsection{Estación mensual}

La estación mensual, utilizando la descomposición aditiva clásica, se muestra como sigue:

 \begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.31]{decom-mensual.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Descomposición clásica de la serie temporal mensual} 
	\label{fig:decomp-mensual}
\end{figure}


Como ya pasaba en la estación diaria, la tendencia es inexistente por la que la establezco como ruido, y trato la estacionalidad con periodo 12 (anual). Tras restarla, la serie temporal resultado es la siguiente:

 \begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.31]{mensual-sinest.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Serie temporal sin estacionalidad} 
	\label{fig:mensual-sinest}
\end{figure}

A continuación, estudio la estacionariedad. El test de Dickey-Fuller da un p-valor de 0.27, por lo que no podemos rechazar la hipótesis de que no es estacionaria. Es clara la necesidad de diferenciar, obteniéndose después un p-valor de 0.01 (confirmando ahora sí la estacionariedad). Vemos las gráficas ACF

 \begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.31]{acf2-mensual.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Gráfica ACF tras diferenciar la serie mensual} 
	\label{fig:acf-mensual}
\end{figure}

y PACF

 \begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.31]{pacf1-mensual.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Gráfica PACF tras diferenciar la serie mensual} 
	\label{fig:pacf-mensual}
\end{figure}


Ambas gráficas nos ilustran para elegir los parámetros de los modelos ARIMA (p=3 por PACF y q=3 por ACF), dando lugar a los modelos AR(3) y MA(3). Ambos dos cumplen los test estadísticos de normalidad y aleatoriedad de los residuos, por lo que son susceptibles de ser examinados, generando las siguientes predicciones para AR(3)

  \begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
 	\centering
 	\includegraphics[scale=0.31]{pred-ar310-mensual.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
 	\caption{Predicción del modelo AR(3) para serie mensual} 
 	\label{fig:ar310}
 \end{figure}

y MA(3)

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.31]{pred-ma013-mensual.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Predicción del modelo MA(3) para serie mensual} 
	\label{fig:ma013}
\end{figure}
 
viéndose que el MA está mas cerca de los valores reales que el AR. A continuación, vemos qué modelo tiene mejor rendimiento. Primero, calculo el error cuadrático medio sobre las predicciones de training y test. Para AR(3), los valores son 0.8920383 y 5.480675, respectivamente. Para MA, 0.862258 y 2.286113, lo que confirma lo que veíamos de forma intuitiva en la gráfica. Además, el criterio AIC nos dice que ambos tienen el mismo número de parámetros libres, 4, pero que el valor de AIC para el modelo de medias móviles es ligeramente menor que el autoregresivo (132.0259 frente a 132.682). Por tanto, uniendo ambas cosas, decido que el modelo de medias móviles es el más conveniente para hacer la predicción. Por tanto, partiendo de la serie completa, realizo todos los pasos antes mencionados para predecir y deshago las operaciones para que los valores resultantes sean reales, obteniéndose la siguiente predicción final, es decir, los valores de temperatura máxima de marzo y abril de 2018:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.31]{prediccion-mensual.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Predicción final de los valores de marzo y abril de 2018 (rojo)} 
	\label{fig:predf}
\end{figure}

Además, como los datos reales son públicos, los incluyo en la gráfica final

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.3]{prediccion-mensual-final.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Predicción final de los valores de marzo y abril de 2018 (rojo) y valores reales (verde)} 
	\label{fig:predmf}
\end{figure}

y calculo su error cuadrático medio (0.907640594619933), viendo que el la predicción se acerca mucho a la real y el error es pequeño, reforzando mi conclusión anterior, ya que en este caso sólo teníamos que predecir dos valores (en vez de 7), por lo que el modelo ARIMA es más efectivo.
\newpage
\section{Bibliografía}

%------------------------------------------------

\bibliography{citas} %archivo citas.bib que contiene las entradas 
\bibliographystyle{plain} % hay varias formas de citar

\end{document}
